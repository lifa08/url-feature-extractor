{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pysafebrowsing import SafeBrowsing\n",
    "import whois\n",
    "from lxml import html\n",
    "import html2text\n",
    "import re\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# url features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url_components(url):\n",
    "    ext_result = tldextract.extract(url)\n",
    "    FQDN = '.'.join(part for part in ext_result if part)\n",
    "    mld = ext_result.domain\n",
    "    RDN = ext_result.registered_domain\n",
    "\n",
    "    FreeURL = ext_result.subdomain + ',' + url.split(FQDN)[1]\n",
    "    protocol = url.split(\"://\")[0]\n",
    "\n",
    "    url_components = {'protocol': protocol,'FQDN': FQDN, 'RDN': RDN, 'mld': mld, 'FreeURL': FreeURL}\n",
    "    return url_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_age_in_days(domain):\n",
    "    show = \"https://input.payapi.io/v1/api/fraud/domain/age/\" + domain\n",
    "    data = requests.get(show).json()\n",
    "    return data['result'] if 'result' in data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is url IP based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if an url includes IP address or not\n",
    "def validate_ip(s):\n",
    "    a = s.split('.')\n",
    "    if len(a) != 4:\n",
    "        return False\n",
    "    for x in a:\n",
    "        if not x.isdigit():\n",
    "            return False\n",
    "        i = int(x)\n",
    "        if i < 0 or i > 255:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if url is in blacklist  by using online blacklisting service\n",
    "\n",
    "Tested three following online blacklisting services:\n",
    "\n",
    "- PhishTank\n",
    "- Google Safebrowsing blacklist\n",
    "- virustotal\n",
    "\n",
    "and figured out that PhishTank API does not seem like working correctly. It marks Twitter and Google as phishing as shown [https://checkurl.phishtank.com/checkurl/index.php?url=https://twitter.com/](https://checkurl.phishtank.com/checkurl/index.php?url=https://twitter.com/), So is not going to use it but leave it here for later to fix it maybe by writing email to ask PhishTank.\n",
    "\n",
    "virustotal API seems to have limitation on how much request you can send within a given time, so when you have mutiple\n",
    "urls to check, better to use time.sleep() between callings to this function. I don't like this, since it makes runing painfully slow, I am thinking maybe to start a thread for it or simply not to use this API. \n",
    "\n",
    "__Note: Safebrowsing API needs to be activated in google cloud before it can be correctly used and google API key is exported in the console environment since it is more secure than writing it here.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This API does not seem like working correctly. It marks Twitter and Google as phishing.\n",
    "def is_phishtank_blacklisted(url):\n",
    "    response = requests.post('https://checkurl.phishtank.com/checkurl/index.php?url=' + url)\n",
    "    # print(response.text)\n",
    "    res = response.content.decode(response.encoding)\n",
    "    root = ET.fromstring(res)\n",
    "\n",
    "    result = root.find('results').find('url0')\n",
    "    is_blacklisted = result.find('in_database').text\n",
    "    return True if is_blacklisted == 'true' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_malicious_in_google_safebrowsing(url):\n",
    "    googleapikey = os.environ['GOOGLEAPIKEY']\n",
    "    s = SafeBrowsing(googleapikey)\n",
    "    response = s.lookup_urls([url])\n",
    "    # print(response)\n",
    "    return (response[url]['malicious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: there is limitation how much request you can send to virustotal API, so when you have mutiple\n",
    "# urls to check, better to use time.sleep() between callings to this function\n",
    "def is_malicious_in_virustotal(url):\n",
    "    virustotal_apikey = os.environ['VIRUSTOTALKEY']\n",
    "    params = {'apikey': virustotal_apikey, 'resource': url}\n",
    "    response = requests.post('https://www.virustotal.com/vtapi/v2/url/report', data=params)\n",
    "    return True if response.json()['positives'] else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHOIS features\n",
    "\n",
    "- Name of the domain provider\n",
    "- Ownership period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_related_features(domain, url_features):\n",
    "    domain_info = whois.whois(domain)\n",
    "    if not domain_info:\n",
    "        return\n",
    "\n",
    "    # print(domain_info.__dict__)\n",
    "    url_features['domain_provider'] = domain_info.registrar if domain_info.registrar else None\n",
    "\n",
    "    if (isinstance(domain_info.expiration_date, list) and\n",
    "        isinstance(domain_info.creation_date, list)):\n",
    "            if (isinstance(domain_info.expiration_date[0], datetime.datetime) and\n",
    "                isinstance(domain_info.creation_date[0], datetime.datetime)):\n",
    "                url_features['domain_valid_period'] = (domain_info.expiration_date[0] - \n",
    "                                                       domain_info.creation_date[0]).days\n",
    "\n",
    "    elif (isinstance(domain_info.expiration_date, datetime.datetime) and\n",
    "          isinstance(domain_info.creation_date, datetime.datetime)):\n",
    "        url_features['domain_valid_period'] = (domain_info.expiration_date - \n",
    "                                               domain_info.creation_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the ranking of url in the majestic_million list\n",
    "\n",
    "The original majestic_million file contains many unnecessary columns for this project and is too large\n",
    "so here we keep only necessary columns by running following two lines of code once\n",
    "\n",
    "```Majestic_million_list = pd.read_csv(\"majestic_million.csv\")[['GlobalRank', 'Domain']]\n",
    "Majestic_million_list.to_csv ('majestic_million.csv', index = True, header=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalRank</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>instagram.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalRank         Domain\n",
       "0           1   facebook.com\n",
       "1           2     google.com\n",
       "2           3    youtube.com\n",
       "3           4    twitter.com\n",
       "4           5  instagram.com"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Majestic_million_list = pd.read_csv(\"majestic_million.csv\")[['GlobalRank', 'Domain']]\n",
    "Majestic_million_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_url_features(url, Majestic_million_list):\n",
    "    # RDNRank default to 1000001 for those websites that are not in the Majestic million list\n",
    "    url_features = {'url': url, 'url_length': len(url),\n",
    "                    'is_blacklisted': False, 'is_IPbased': False,\n",
    "                    'domain_age':None, 'FreeURL_dot_cnt': 0,\n",
    "                    'level_domain_cnt': None, 'FQDN_length': None,\n",
    "                    'mld_length': None, 'url_terms_cnt': 0,\n",
    "                    'RDNRank': 1000001, 'domain_provider': None,\n",
    "                    'domain_valid_period': None\n",
    "                   }\n",
    "\n",
    "    # Tried also phishtank API but it does not seem like working correctly\n",
    "    url_features['is_blacklisted'] = is_malicious_in_virustotal(url) or is_malicious_in_google_safebrowsing(url)\n",
    "\n",
    "    url_components = parse_url_components(url)\n",
    "    url_features['is_IPbased'] = validate_ip(url_components['FQDN'])\n",
    "\n",
    "    # url has domain\n",
    "    if not url_features['is_IPbased']:\n",
    "        domain_age = get_domain_age_in_days(url_components['RDN'])\n",
    "        url_features['domain_age'] = domain_age if domain_age else None\n",
    "\n",
    "        url_features['level_domain_cnt'] = url_components['FQDN'].count('.') + 1\n",
    "        url_features['FQDN_length'] = len(url_components['FQDN'])\n",
    "        url_features['mld_length'] = len(url_components['mld'])\n",
    "\n",
    "        # update the domain related features\n",
    "        get_domain_related_features(url_components['RDN'], url_features)\n",
    " \n",
    "        # url_terms_cnt = the number of terms in FQDN + the number of terms in the remaining part of url\n",
    "        for FQDN_part in url_components['FQDN'].split('.'):\n",
    "            url_features['url_terms_cnt'] += len(FQDN_part.split('-'))\n",
    "\n",
    "\n",
    "    url_features['FreeURL_dot_cnt'] = url_components['FreeURL'].count('.')\n",
    "\n",
    "    # url_terms_cnt = the number of terms in FQDN + the number of terms in the remaining part of url\n",
    "    for parts in url_components['FreeURL'].split(',')[1:]:\n",
    "        for part in parts.split('/'):\n",
    "            if part:\n",
    "                url_features['url_terms_cnt'] += len(part.split('-'))\n",
    "\n",
    "    RDN_row = Majestic_million_list[Majestic_million_list['Domain'] == url_components['RDN']]\n",
    "    if len(RDN_row):\n",
    "        url_features['RDNRank'] = RDN_row.iloc[0]['GlobalRank']\n",
    "\n",
    "    # Note the purpose here is not to have RDN as a feature, but as a way to pass it to later functions\n",
    "    # to get features related to RDN and avoid parse it again there\n",
    "    url_features['mld'] = url_components['mld']\n",
    "\n",
    "    #print(url_features)\n",
    "    return url_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note some of these urls are live phishing sites (as of 2019-03-21) use with caution!\n",
    "# More can be found at https://www.phishtank.com/\n",
    "example_urls = [\"https://www.slideshare.net/weaveworks/client-side-monitoring-with-prometheus\",\n",
    "                \"http://cartaobndes.gov.br.cv31792.tmweb.ru/\",\n",
    "                \"https://paypal.co.uk.yatn.eu/m/\",\n",
    "                \"http://college-eisk.ru/cli/\",\n",
    "                \"https://dotpay-platnosc3.eu/dotpay/\",\n",
    "                \"https://www.amazon.co.uk/ap/signin?encoding=UTF8\",\n",
    "                \"http://192.168.0.1/paypal.cgi?fixaccount\"\n",
    "               ]\n",
    "\n",
    "urls_features = []\n",
    "for url in example_urls:\n",
    "    urls_features.append(analyze_url_features(url, Majestic_million_list))\n",
    "    # To curcumvent the limits set by virustotal on the API calls within a given time\n",
    "    time.sleep(30)\n",
    "#print(urls_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_features_df = pd.DataFrame(urls_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_length</th>\n",
       "      <th>is_blacklisted</th>\n",
       "      <th>is_IPbased</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>FreeURL_dot_cnt</th>\n",
       "      <th>level_domain_cnt</th>\n",
       "      <th>FQDN_length</th>\n",
       "      <th>mld_length</th>\n",
       "      <th>url_terms_cnt</th>\n",
       "      <th>RDNRank</th>\n",
       "      <th>domain_provider</th>\n",
       "      <th>domain_valid_period</th>\n",
       "      <th>mld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.slideshare.net/weaveworks/client-s...</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>MarkMonitor, Inc.</td>\n",
       "      <td>6209.0</td>\n",
       "      <td>slideshare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://cartaobndes.gov.br.cv31792.tmweb.ru/</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3910</td>\n",
       "      <td>TIMEWEB-RU</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>tmweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paypal.co.uk.yatn.eu/m/</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1000001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yatn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://college-eisk.ru/cli/</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1000001</td>\n",
       "      <td>R01-RU</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>college-eisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dotpay-platnosc3.eu/dotpay/</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1000001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dotpay-platnosc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.amazon.co.uk/ap/signin?encoding=UTF8</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>194</td>\n",
       "      <td>Amazon.com, Inc. t/a Amazon.com, Inc. [Tag = A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://192.168.0.1/paypal.cgi?fixaccount</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1000001</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.168.0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  url_length  \\\n",
       "0  https://www.slideshare.net/weaveworks/client-s...          76   \n",
       "1        http://cartaobndes.gov.br.cv31792.tmweb.ru/          43   \n",
       "2                    https://paypal.co.uk.yatn.eu/m/          31   \n",
       "3                        http://college-eisk.ru/cli/          27   \n",
       "4                https://dotpay-platnosc3.eu/dotpay/          35   \n",
       "5   https://www.amazon.co.uk/ap/signin?encoding=UTF8          48   \n",
       "6           http://192.168.0.1/paypal.cgi?fixaccount          40   \n",
       "\n",
       "   is_blacklisted  is_IPbased  domain_age  FreeURL_dot_cnt  level_domain_cnt  \\\n",
       "0           False       False      5108.0                0               3.0   \n",
       "1            True       False      5023.0                3               6.0   \n",
       "2            True       False         NaN                2               5.0   \n",
       "3            True       False      3091.0                0               2.0   \n",
       "4           False       False         NaN                0               2.0   \n",
       "5           False       False      8642.0                0               4.0   \n",
       "6           False        True         NaN                1               NaN   \n",
       "\n",
       "   FQDN_length  mld_length  url_terms_cnt  RDNRank  \\\n",
       "0         18.0        10.0              9       91   \n",
       "1         35.0         5.0              6     3910   \n",
       "2         20.0         4.0              6  1000001   \n",
       "3         15.0        12.0              4  1000001   \n",
       "4         19.0        16.0              4  1000001   \n",
       "5         16.0         6.0              6      194   \n",
       "6          NaN         NaN              1  1000001   \n",
       "\n",
       "                                     domain_provider  domain_valid_period  \\\n",
       "0                                  MarkMonitor, Inc.               6209.0   \n",
       "1                                         TIMEWEB-RU               5114.0   \n",
       "2                                               None                  NaN   \n",
       "3                                             R01-RU               3288.0   \n",
       "4                                               None                  NaN   \n",
       "5  Amazon.com, Inc. t/a Amazon.com, Inc. [Tag = A...                  NaN   \n",
       "6                                               None                  NaN   \n",
       "\n",
       "                mld  \n",
       "0        slideshare  \n",
       "1             tmweb  \n",
       "2              yatn  \n",
       "3      college-eisk  \n",
       "4  dotpay-platnosc3  \n",
       "5            amazon  \n",
       "6       192.168.0.1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_features_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page visit features\n",
    "\n",
    "Features that need to be obtained by actually visiting the page, thus <span style=\"color:red\">**be cautions and use only legitimate website to test following functions**.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get redirect chain which can then be used to calculate the number of redirects and landing url\n",
    "def get_redirect_chain(url):\n",
    "    res = requests.get(url)\n",
    "    redirect_number = len(res.history)\n",
    "    landing_url = res.url\n",
    "\n",
    "    redirect_chain = []\n",
    "    if res.history:\n",
    "        for responses in res.history:\n",
    "            redirect_chain.append(responses.url)\n",
    "\n",
    "    # adding landing url\n",
    "    redirect_chain.append(landing_url)\n",
    "    return redirect_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse <a> tag href urls\n",
    "def get_website_hyperlinks(tree):\n",
    "    hyperlinks = []\n",
    "    for atag in tree.xpath('//a[@href]'):\n",
    "        hyperlinks.append(atag.attrib['href'])\n",
    "        # print(atag.attrib['href'], atag.text_content())\n",
    "    return hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the plain text in the body\n",
    "def get_website_text(page_content):\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = True\n",
    "    text = h.handle(page_content)\n",
    "    # Escapte special characters and spaces\n",
    "    return \" \".join(re.findall(r\"(?i)\\b[a-z]+\\b\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse <img> tag src urls\n",
    "def get_website_iURLs(tree):\n",
    "    iURLs = []\n",
    "    for imgtag in tree.xpath('//img[@src]'):\n",
    "        iURLs.append(imgtag.attrib['src'])\n",
    "    return iURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse <style> tags\n",
    "def get_website_style_tags(tree):\n",
    "    style_tags = []\n",
    "    for element in tree.xpath('//@style'):\n",
    "        # print(element)\n",
    "        style_tags.append(element)\n",
    "    return style_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse SS_URL (external style sheets)\n",
    "def get_website_SS_URLs(tree):\n",
    "    SS_URLs = []\n",
    "    for linktag in tree.xpath('//link[(@rel=\"stylesheet\" or @type=\"text/css\") and @href]'):\n",
    "        SS_URLs.append(linktag.attrib['href'])\n",
    "    return SS_URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse web contents that are needed for extracting page visit features\n",
    "def parse_web_content(url):\n",
    "    web_content = {'title': '', 'text': '',\n",
    "                   'input_number': 0, 'iframe_number': 0,\n",
    "                  'img_urls': [], 'href_links': [],\n",
    "                  'styles': [], 'SS_urls': []}\n",
    "\n",
    "    page = requests.get(url)\n",
    "    page_content = page.content.decode(page.encoding)\n",
    "    tree = html.fromstring(page_content)\n",
    "\n",
    "    title_raw = tree.xpath('//title')[0].text_content()\n",
    "    web_content['title'] = \" \".join(re.findall(r\"(?i)\\b[a-z]+\\b\", title_raw))\n",
    "    web_content['text'] = get_website_text(page_content)\n",
    "    web_content['iframe_number'] = len(tree.xpath('//iframe'))\n",
    "    web_content['input_number'] = len(tree.xpath('//input'))\n",
    "    web_content['img_urls'] = get_website_iURLs(tree)\n",
    "    web_content['href_links'] = get_website_hyperlinks(tree)\n",
    "    web_content['styles'] = get_website_style_tags(tree)\n",
    "    web_content['SS_urls'] = get_website_SS_URLs(tree)\n",
    "\n",
    "    return web_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the FreeURL of an url\n",
    "def get_FreeURL(url):\n",
    "    # relative reference\n",
    "    regex = re.compile(r'^(?:http|ftp)s?://', re.IGNORECASE)\n",
    "    if not re.match(regex, url):\n",
    "        return ''\n",
    "\n",
    "    ext_result = tldextract.extract(url)\n",
    "    FQDN = '.'.join(part for part in ext_result if part)\n",
    "\n",
    "    FreeURL = ext_result.subdomain + ',' + url.split(FQDN)[1]\n",
    "    return FreeURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if main level domain in the FreeURL of href links\n",
    "def is_mld_in_href_FreeURL(href_links, mld):\n",
    "    for href_link in href_links:\n",
    "        FreeURL = get_FreeURL(href_link)\n",
    "        if mld in FreeURL:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison features\n",
    "\n",
    "Features that are constructed by **comparing the characteristics of a input page and those of its homepage**. Refer from [DeltaPhish](https://arxiv.org/pdf/1707.00317.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the homepage url of a given url\n",
    "def get_url_homepage(url):\n",
    "    ext_result = tldextract.extract(url)\n",
    "    protocol = url.split(\"://\")[0]\n",
    "\n",
    "    homepage_url =  protocol + \"://\"\n",
    "    if ext_result.subdomain == 'www':\n",
    "        homepage_url += 'www.'\n",
    "\n",
    "    homepage_url += ext_result.registered_domain\n",
    "    if url[-1] == '/':\n",
    "        homepage_url += '/'\n",
    "\n",
    "    return homepage_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    if not len(list1) and not len(list1):\n",
    "        return 1\n",
    "        \n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_comparison_features():\n",
    "    return {'hyper_link_jaccard': 1, 'hyper_link_mld_jaccard': 1,\n",
    "            'ss_jaccard': 1, 'ss_url_jaccard': 1,\n",
    "            'ss_url_mld_jaccard': 1, 'img_url_jaccard': 1,\n",
    "            'img_url_mld_jaccard': 1, 'title_jaccard': 1,\n",
    "            'is_hompage_linked': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get main level domain of given urls\n",
    "def get_mld_of_urls(urls):\n",
    "    mlds = []\n",
    "    for url in urls:\n",
    "        mlds.append(tldextract.extract(url).domain)\n",
    "    return mlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comparison_features(homepage_content, inputpage_content):\n",
    "    comparison_features = initialize_comparison_features()\n",
    "    comparison_features['hyper_link_jaccard'] = jaccard_similarity(homepage_content['href_links'],\n",
    "                                                                 inputpage_content['href_links'])\n",
    "    homepage_hyper_link_mlds = get_mld_of_urls(homepage_content['href_links'])\n",
    "    inputpage_hyper_link_mlds = get_mld_of_urls(inputpage_content['href_links'])    \n",
    "    comparison_features['hyper_link_mld_jaccard'] = jaccard_similarity(homepage_hyper_link_mlds,\n",
    "                                                                      inputpage_hyper_link_mlds)\n",
    "\n",
    "    comparison_features['ss_jaccard'] = jaccard_similarity(homepage_content['styles'],\n",
    "                                                          inputpage_content['styles'])\n",
    "\n",
    "   # external style sheets \n",
    "    comparison_features['ss_url_jaccard'] = jaccard_similarity(homepage_content['SS_urls'],\n",
    "                                                          inputpage_content['SS_urls'])\n",
    "    homepage_ss_url_mlds = get_mld_of_urls(homepage_content['SS_urls'])\n",
    "    inputpage_ss_url_mlds = get_mld_of_urls(inputpage_content['SS_urls'])    \n",
    "    comparison_features['ss_url_mld_jaccard'] = jaccard_similarity(homepage_ss_url_mlds,\n",
    "                                                                   inputpage_ss_url_mlds)\n",
    "\n",
    "    # image url\n",
    "    comparison_features['img_url_jaccard'] = jaccard_similarity(homepage_content['img_urls'],\n",
    "                                                          inputpage_content['img_urls'])\n",
    "    homepage_img_url_mlds = get_mld_of_urls(homepage_content['img_urls'])\n",
    "    inputpage_img_url_mlds = get_mld_of_urls(inputpage_content['img_urls'])    \n",
    "    comparison_features['img_url_mld_jaccard'] = jaccard_similarity(homepage_img_url_mlds,\n",
    "                                                                   inputpage_img_url_mlds)\n",
    "\n",
    "\n",
    "    # title\n",
    "    comparison_features['title_jaccard'] = jaccard_similarity(homepage_content['title'].split(' '),\n",
    "                                                          inputpage_content['title'].split(' '))\n",
    "\n",
    "    return comparison_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the features that need to be obtained by actually sending http request to the page\n",
    "def analyze_page_visit_features(url, mld_of_starting_url):\n",
    "    page_visit_features = {'redirect_number': 0, 'landing_url': url,\n",
    "                           'title_term_cnt': 0, 'text_term_cnt': 0,\n",
    "                           'iframe_number': 0, 'input_number': 0,\n",
    "                           'image_number': 0, 'href_number': 0,\n",
    "                           'mld_equals': False, 'starting_mld_in_title': False,\n",
    "                           'starting_mld_in_text': False, 'starting_mld_in_href_FreeURL':False,\n",
    "                           'landing_mld_in_title': False, 'landing_mld_in_text': False,\n",
    "                           'landing_mld_in_href_FreeURL': False\n",
    "                          }\n",
    "\n",
    "    redirect_chain = get_redirect_chain(url)\n",
    "    landing_url = redirect_chain[-1]\n",
    "\n",
    "    page_visit_features['redirect_number'] = len(redirect_chain) - 1\n",
    "    page_visit_features['landing_url'] = landing_url\n",
    "\n",
    "    web_content = parse_web_content(url)\n",
    "    page_visit_features['title_term_cnt'] = len(web_content['title'].split(' '))\n",
    "    page_visit_features['text_term_cnt'] = len(web_content['text'].split(' '))\n",
    "    page_visit_features['iframe_number'] = web_content['iframe_number']\n",
    "    page_visit_features['input_number'] = web_content['input_number']\n",
    "    page_visit_features['image_number'] = len(web_content['img_urls'])\n",
    "    page_visit_features['href_number'] = len(web_content['href_links'])\n",
    "\n",
    "    page_visit_features['starting_mld_in_title'] = mld_of_starting_url in web_content['title'].lower()\n",
    "    page_visit_features['starting_mld_in_text'] = mld_of_starting_url in web_content['text'].lower()\n",
    "    mld_of_landing_url =  tldextract.extract(landing_url).domain  \n",
    "    if mld_of_landing_url == mld_of_starting_url:\n",
    "        page_visit_features['mld_equals'] = True\n",
    "        page_visit_features['landing_mld_in_title'] = page_visit_features['starting_mld_in_title']\n",
    "        page_visit_features['landing_mld_in_text'] = page_visit_features['starting_mld_in_text']\n",
    "    else:\n",
    "        page_visit_features['landing_mld_in_title'] = mld_of_landing_url in web_content['title'].lower()\n",
    "        page_visit_features['landing_mld_in_text'] = mld_of_landing_url in web_content['text'].lower()\n",
    "\n",
    "    page_visit_features['starting_mld_in_href_FreeURL'] = is_mld_in_href_FreeURL(web_content['href_links'],\n",
    "                                                                                 mld_of_starting_url)\n",
    "    page_visit_features['landing_mld_in_href_FreeURL'] = is_mld_in_href_FreeURL(web_content['href_links'],\n",
    "                                                                                 mld_of_landing_url)\n",
    "\n",
    "\n",
    "    # comparison features\n",
    "    comparison_features = initialize_comparison_features()\n",
    "    homepage_url = get_url_homepage(url)\n",
    "    if homepage_url != url:\n",
    "        homepage_content = parse_web_content(homepage_url)\n",
    "        comparison_features = analyze_comparison_features(homepage_content, web_content)\n",
    "\n",
    "        comparison_features['is_hompage_linked'] = 1 if homepage_url in web_content['href_links'] else 0\n",
    "\n",
    "    page_visit_features.update(comparison_features)\n",
    "    return page_visit_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_url_list') as f:\n",
    "    test_urls = [line.strip() for line in f.readlines()]\n",
    "\n",
    "all_features = []\n",
    "# in the test_url_list file, the first 5 urls are legitimate and thus can be tested safely here\n",
    "for url in test_urls[:5]:\n",
    "    features_dict = analyze_url_features(url, Majestic_million_list)\n",
    "    features_dict.update(analyze_page_visit_features(url, features_dict['mld']))\n",
    "    del features_dict[\"mld\"]\n",
    "    all_features.append(features_dict)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_length</th>\n",
       "      <th>is_blacklisted</th>\n",
       "      <th>is_IPbased</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>FreeURL_dot_cnt</th>\n",
       "      <th>level_domain_cnt</th>\n",
       "      <th>FQDN_length</th>\n",
       "      <th>mld_length</th>\n",
       "      <th>url_terms_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>landing_mld_in_href_FreeURL</th>\n",
       "      <th>hyper_link_jaccard</th>\n",
       "      <th>hyper_link_mld_jaccard</th>\n",
       "      <th>ss_jaccard</th>\n",
       "      <th>ss_url_jaccard</th>\n",
       "      <th>ss_url_mld_jaccard</th>\n",
       "      <th>img_url_jaccard</th>\n",
       "      <th>img_url_mld_jaccard</th>\n",
       "      <th>title_jaccard</th>\n",
       "      <th>is_hompage_linked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://twitter.com/</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7374</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4556</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.google.com/</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8232</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.yahoo.com/</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.co.uk/ap/signin?encoding=UTF8</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8642</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url  url_length  \\\n",
       "0                               http://twitter.com/          19   \n",
       "1                               https://github.com/          19   \n",
       "2                            http://www.google.com/          22   \n",
       "3                             http://www.yahoo.com/          21   \n",
       "4  https://www.amazon.co.uk/ap/signin?encoding=UTF8          48   \n",
       "\n",
       "   is_blacklisted  is_IPbased  domain_age  FreeURL_dot_cnt  level_domain_cnt  \\\n",
       "0           False       False        7374                0                 2   \n",
       "1           False       False        4556                0                 2   \n",
       "2           False       False        8232                0                 3   \n",
       "3           False       False        9203                0                 3   \n",
       "4           False       False        8642                0                 4   \n",
       "\n",
       "   FQDN_length  mld_length  url_terms_cnt  ...  landing_mld_in_href_FreeURL  \\\n",
       "0           11           7              2  ...                         True   \n",
       "1           10           6              2  ...                         True   \n",
       "2           14           6              3  ...                         True   \n",
       "3           13           5              3  ...                         True   \n",
       "4           16           6              6  ...                        False   \n",
       "\n",
       "  hyper_link_jaccard  hyper_link_mld_jaccard  ss_jaccard ss_url_jaccard  \\\n",
       "0                1.0                1.000000         1.0            1.0   \n",
       "1                1.0                1.000000         1.0            1.0   \n",
       "2                1.0                1.000000         1.0            1.0   \n",
       "3                1.0                1.000000         1.0            1.0   \n",
       "4                0.0                0.083333         0.0            0.0   \n",
       "\n",
       "   ss_url_mld_jaccard  img_url_jaccard  img_url_mld_jaccard  title_jaccard  \\\n",
       "0                 1.0              1.0                  1.0            1.0   \n",
       "1                 1.0              1.0                  1.0            1.0   \n",
       "2                 1.0              1.0                  1.0            1.0   \n",
       "3                 1.0              1.0                  1.0            1.0   \n",
       "4                 1.0              0.0                  0.5            0.0   \n",
       "\n",
       "   is_hompage_linked  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df = pd.DataFrame(all_features)\n",
    "all_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the extracted features to csv file\n",
    "all_features_df.to_csv ('url_features.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
